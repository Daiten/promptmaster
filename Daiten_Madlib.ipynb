{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Daiten Madlib",
      "provenance": [],
      "collapsed_sections": [],
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## [Neuralism](https://twitter.com/NeuralismAI) Prompt Generator with [MadLib](https://colab.research.google.com/drive/1gGwD0zDvyx0OnJU4KLjE8HrwnTlzI2rS)\n",
        "\n",
        "This is a more advanced version of the [previous prompt generator](https://colab.research.google.com/drive/1mrlY_mc-HdIxEHILY2BvA9u0mOjD2Ze5). It can have specific prompt templates instead of one default template like from the other one.\n",
        "\n",
        "\n",
        "\n",
        "Features:\n",
        "- custom prompt template input field\n",
        "- prompt weights\n",
        "- vqgan/diffusion format toggle\n",
        "- text file output\n",
        "\n",
        "To do:\n",
        "- add more templates\n",
        "\n",
        "\n",
        "Please feel free to submit prompt templates by sending them to Thor#0897 on discord or [thors_thunder04](https://twitter.com/thors_thunder04) on twitter. Since that is what will help make this a great prompt generator. With as many templates as possible.\n",
        "\n",
        "All current prompt templates can be found [here](https://github.com/sanzelda/prompt_gen/blob/main/templates.py)"
      ],
      "metadata": {
        "id": "ipGoCiKS2zor"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tDZEYe5V4o2K"
      },
      "outputs": [],
      "source": [
        "#@markdown # Download prompt lists\n",
        "!git clone https://github.com/Daiten/promptmaster.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Madlib prompt module by [@remi_durant](https://twitter.com/remi_durant)\n",
        "import re\n",
        "import random\n",
        "import copy\n",
        "import inflect\n",
        "engine = inflect.engine()\n",
        "\n",
        "def madlib_template( templates, global_lookup = {}, \n",
        "        options = { \n",
        "            \"avoid_repeats\" : True, \n",
        "            \"fix_indefinite_articles\" : True \n",
        "        }):\n",
        "\n",
        "    # get prompt template weights and pick one\n",
        "    weights = [ p.get('weight') or 1 for p in templates]\n",
        "    t = random.choices( templates, weights=weights, k=1 )[0]\n",
        "    \n",
        "    lookup = { **global_lookup, **(t.get('lookup') or {}) }\n",
        "    lookup_cardstack = {}\n",
        "\n",
        "    def on_madlib_sub( match ):\n",
        "        opt = match.group(2).split('|')\n",
        "\n",
        "        key = opt[0]\n",
        "\n",
        "        # do a lookup if there's only one option in the brackets\n",
        "        if len(opt) == 1 and lookup.get(key):\n",
        "\n",
        "            # discard used words to avoid repeats, unless no words remain\n",
        "            if options[\"avoid_repeats\"]:\n",
        "\n",
        "                if len(lookup_cardstack.get(key) or []) == 0:\n",
        "                    lookup_cardstack[key] = copy.copy( lookup[key] )\n",
        "\n",
        "                g2 = random.choice( lookup_cardstack[key] )\n",
        "                lookup_cardstack[key].remove(g2)\n",
        "\n",
        "            else:\n",
        "                g2 = random.choice( lookup.get(key) )\n",
        "          \n",
        "        # or just pick one of the given options  \n",
        "        else:\n",
        "            g2 = random.choice( opt )\n",
        "\n",
        "        g1 = match.group(1)\n",
        "        if g1 is not None:\n",
        "\n",
        "            # if the previous word is 'A' or 'An', figure out if the 'n' is needed\n",
        "            if options[\"fix_indefinite_articles\"]:\n",
        "                    if g2[0].lower() in list(\"aeiou\"):\n",
        "                        g1 = g1[0] + 'n'\n",
        "                    else:\n",
        "                        g1 = g1[0]\n",
        "            g2 = g1 + ' ' + g2\n",
        "            \n",
        "        return g2\n",
        "    \n",
        "    # find madlib spots, and replace\n",
        "    return re.sub(r\"(\\b[Aa]n? )?{([^{}]*)}\", on_madlib_sub, t['prompt'] )\n",
        "\n",
        "thing = 12"
      ],
      "metadata": {
        "id": "_eoGjXTw6qp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How to add custom prompts\n"
      ],
      "metadata": {
        "id": "8IfNAZ8plLXL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "There are the different variables you can put in your prompts:\n",
        "\n",
        "*   `{adjective}`\n",
        "*   `{animal}`\n",
        "*   `{artist}`\n",
        "*   `{color}`\n",
        "*   `{thing}`\n",
        "*   `{shape}`\n",
        "*   `{style}`\n",
        "*   `{location}`\n",
        "*   `{element}` [water, fire, earth, air] (not on the github)\n",
        "\n",
        "The word lists to these variables can be found [here](https://github.com/sanzelda/prompt_gen).\n",
        "\n",
        "\n",
        "There is also a way to choose a random word/phrase without these variables.\n",
        "If you format a prompt like this: \"It's cold `{today|tonight|in here}`, so I need a jacket.\" or \"I need to `{sit down|eat something}`\"\n",
        "\n",
        "It will choose at random, either \"today\", \"tonight\" or \"in here\" for the first example. And either \"sit down\" or \"eat something\" for the second example.\n",
        "\n",
        "---\n",
        "You can also add weights to your prompts to change their frequency by adding a number after `-!-` in your template.\n",
        "\n",
        "Here is an example of how they work:\n",
        "\n",
        "The default weight of a prompt is 1.\n",
        "\n",
        "If you have 2 prompt templates, one with the default weight of 1, and one with a weight of 2. The frequency of the first prompt will be `1/3` and the frequency of the second prompt will be `2/3`. \n",
        "\n",
        "In other words, the probability of landing on a prompt template is: `weight of the template/sum of all weights`\n",
        "\n",
        "\n",
        "Example of a custom template with a weight of 3 for `custom_promt_templates`:\n",
        "\n",
        "\"There are thousands of `{animal}` in the sky -!- 3\"\n"
      ],
      "metadata": {
        "id": "I_qGeWdOoBkF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate random prompt"
      ],
      "metadata": {
        "id": "CpzByy_wn47J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "amount_of_prompts =  100#@param {type:\"integer\"}\n",
        "VQGAN_prompt = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown The outputs will be saved to /content/prompt_gen_output.txt .\n",
        "#@markdown Also, if you run this cell more than once, it will \n",
        "#@markdown simply add the new prompts in addition to the previous ones.\n",
        "txt_file_output = False #@param {type:\"boolean\"}\n",
        "\n",
        "# imports the prompt templates\n",
        "from promptmaster.templates import *\n",
        "\n",
        "\n",
        "prompt_lookup = {}\n",
        "prompt_lookup[\"adjective\"] = open(\"/content/promptmaster/adjectives.txt\").read().splitlines()\n",
        "prompt_lookup[\"animal\"] = open(\"/content/promptmaster/animals.txt\").read().splitlines()\n",
        "prompt_lookup[\"artist\"] = open(\"/content/promptmaster/artists.txt\").read().splitlines()\n",
        "prompt_lookup[\"color\"] = open(\"/content/promptmaster/colors.txt\").read().splitlines()\n",
        "prompt_lookup[\"thing\"] = open(\"/content/promptmaster/things.txt\").read().splitlines()\n",
        "prompt_lookup[\"shape\"] = open(\"/content/promptmaster/shapes.txt\").read().splitlines()\n",
        "prompt_lookup[\"style\"] = open(\"/content/promptmaster/styles.txt\").read().splitlines()\n",
        "prompt_lookup[\"location\"] = open(\"/content/promptmaster/locations.txt\").read().splitlines()\n",
        "prompt_lookup[\"being\"] = open(\"/content/promptmaster/beings.txt\").read().splitlines()\n",
        "prompt_lookup[\"of\"] = open(\"/content/promptmaster/of_something.txt\").read().splitlines()\n",
        "prompt_lookup[\"verb\"] = open(\"/content/promptmaster/verbs.txt\").read().splitlines()\n",
        "prompt_lookup[\"intrans\"] = open(\"/content/promptmaster/intrans.txt\").read().splitlines()\n",
        "prompt_lookup[\"clothes\"] = open(\"/content/promptmaster/clothes.txt\").read().splitlines()\n",
        "prompt_lookup[\"transport\"] = open(\"/content/promptmaster/transports.txt\").read().splitlines()\n",
        "\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown Custom Prompts\n",
        "#@markdown separate templates with `||` and weights to a template with `-!-`\n",
        "custom_prompt_templates = \"\" #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "# so that it doesn't generate blanks\n",
        "if custom_prompt_templates.strip() != \"\":\n",
        "    \n",
        "    custom_prompt_templates = custom_prompt_templates.split(\"||\")\n",
        "    for prompt_template in custom_prompt_templates:\n",
        "        prompt_template = prompt_template.split(\"-!-\")\n",
        "        if len(prompt_template) == 2:\n",
        "            prompt_templates.append({\n",
        "                \"prompt\": prompt_template[0].strip(),\n",
        "                \"weight\": float(prompt_template[1].strip())\n",
        "                })\n",
        "        else:\n",
        "            prompt_templates.append({\"prompt\": prompt_template[0].strip()})\n",
        "\n",
        "\n",
        "# these are here just for testing things, they don't do anything otherwise.\n",
        "test_prompts = [\n",
        "                {\n",
        "                    \"prompt\": \"tests 1 {lookup}\"\n",
        "                },\n",
        "                {\n",
        "                    \"prompt\": \"test 2 {lookup}\"\n",
        "                }\n",
        "]\n",
        "test_lookup = {\n",
        "    \"lookup\": [\"one\", \"two\", \"three\"],\n",
        "    \"lookdown\": [\"four\", \"five\", \"six\"]\n",
        "}\n",
        "\n",
        "if txt_file_output:\n",
        "    txtFile = open(\"prompt_gen_output.txt\", \"a\")\n",
        "\n",
        "for i in range(amount_of_prompts):\n",
        "\n",
        "    prompt = madlib_template(prompt_templates, prompt_lookup)\n",
        "\n",
        "    if VQGAN_prompt:\n",
        "        prompt = prompt.replace(\",\", \" |\")\n",
        "    \n",
        "    print(prompt)\n",
        "    if txt_file_output:\n",
        "        txtFile.write(prompt+\"\\n\")\n",
        "        \n",
        "if txt_file_output:\n",
        "    txtFile.close()\n"
      ],
      "metadata": {
        "id": "vdBq45oJ5IXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "8Mi-igZ-7Vvx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}